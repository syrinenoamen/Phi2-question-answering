This work is on adapting Microsoft Large Language Model Phi-2 to the application of a university-level teaching assistant, capable of answering and reasoning about highly specialized questions across several different fields. I use fine tuning to expose the model to high level questions and reasoning, and Direct Preference Optimization to prefer answers which explain their reasoning in depth. I explored prompting techniques such as few-shot learning and chain-of-thought reasoning to improve model performance. Finally, I employ quantization to improve the model's inference speed and even to be able to run it on end users' devices. The final model, quantized and fine-tuned, offers 73% and 77% accuracy on Winograd Grande and PIQA, two common sense reasoning benchmarks, 44% and 43% on MMLU's Machine Learning and College Computer Science tasks, two coding benchmarks. These represent only minor degradations or even improvements over the base model, while my quantized model takes only 1.8GB of disk space, a reduction of âˆ¼4x.
